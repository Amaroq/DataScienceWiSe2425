{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a2d2714",
   "metadata": {},
   "source": [
    "# Data Bias: Fairness Gerrymandering\n",
    "\n",
    "In this exercise you will slip into the role of data scientists that are requested as data experts for a judicial dispute.\n",
    "The scenario in dispute is as follows:\n",
    "\n",
    "A woman of color applied for a job at the company *MajorEngine*, but got rejected.\n",
    "She suspects that she got turned down for racist and sexist reasons, *i.e.* because she is a woman of color.\n",
    "*MajorEngine* refutes this claim and provides employment records in court in order to disprove the claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f63ab60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>hispanic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender      race\n",
       "0    male     white\n",
       "1  female     white\n",
       "2  female     white\n",
       "3    male     white\n",
       "4    male  hispanic"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "        \n",
    "# load the data from the file 'hiring_records_MajorEngine.csv' and inspect the first rows with the pandas function 'head'\n",
    "data = pd.read_csv(\"./hiring_records_MajorEngine.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1786d904",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "\n",
    "Slip into the role of a data scientist hired by *MajorEngine* in order to show that based on the employment records \n",
    "\n",
    "__(a)__ the company has no racist hiring policy, and \n",
    "\n",
    "__(b)__ has no strongly sexist hiring policy. Note that according to the [2020 U.S. census](https://en.wikipedia.org/wiki/Race_and_ethnicity_in_the_United_States), the perfect, expected percentage of white employees would be 61.6%.\n",
    "\n",
    "Use bar charts to convey your findings to a lay person and write a comment that explains your figure in favor of *MajorEngine*.\n",
    "\n",
    "*Hint: While exploring the dataset, look at the ratio of white employees vs. non-white employees, and the ratio of male employees vs. non-male employees. It can also be useful to create a plot of the ideal distribution as comparison.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7da46571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'white': 0.7, 'hispanic': 0.171, 'black': 0.108, 'asian': 0.021}\n"
     ]
    }
   ],
   "source": [
    "# Part (a): show that MajorEngine has no strongly racist hiring policy\n",
    "employ_num = data.shape[0]\n",
    "races = data[\"race\"].unique()\n",
    "\n",
    "race_percentage = {}\n",
    "\n",
    "for race in races:\n",
    "    race_percentage[race] = (data[data[\"race\"] == race].shape[0]) / float(employ_num)\n",
    " \n",
    "print(race_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1f6165",
   "metadata": {},
   "source": [
    "The result seems to imply a slight racist trend according to the 2020 US census, but according to a [newer study](https://usafacts.org/data/topics/people-society/population-and-demographics/our-changing-population/) from 2021, the hiring policy could be valued as a bit more racist. But the problem about this argumentation is though, that even if there are more white employees than the ethnicity statistics imply, the reality is, that with white people being privileged, there also is a trend of white-people working in jobs with more academical qualifications than non-white people.\n",
    "\n",
    "In summary this means, that depending on the context of this being an academic job or not, the results could imply a less racist employment scheme, because the general distribution of different races should not be assumed to be the same when talking about different academic qualifications, because non-white people have a harder time getting the same qualifications as white-people because the system itself is racist and historically spoken, non-white people have lived in worse environments in America (i.e. slums etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c71d2528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'male': 0.5, 'female': 0.497, 'non-binary': 0.003}\n"
     ]
    }
   ],
   "source": [
    "# Part (b): Show that MajorEngine has no sexist hiring policy\n",
    "\n",
    "employ_num = data.shape[0]\n",
    "genders = data[\"gender\"].unique()\n",
    "\n",
    "gender_percentage = {}\n",
    "\n",
    "for gender in genders:\n",
    "    gender_percentage[gender] = (data[data[\"gender\"] == gender].shape[0]) / float(employ_num)\n",
    " \n",
    "print(gender_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d36bd7",
   "metadata": {},
   "source": [
    "These results seem to imply that the hiring policy is not sexist, since the distribution of males and females was 49.5% to 50.5% in the US (2021, [source](https://www.census.gov/data/tables/time-series/demo/popest/2020s-national-detail.html)).  \n",
    "I have not found any statistics of how many people identify as non-binary in the US, so I can't check if the hiring policy is queer-phobic, but at this low sample-size there are many factors that could contextualize the percentage (f.e. non-binary people being registered with a binary gender)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2d2664",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Slip into the role of a data scientist that works pro bono in order to demonstrate that *MajorEngine* has exhibited a bias in the past and thus is likely to have treated the woman of color unfairly.\n",
    "\n",
    "Use a confusion matrix to convey your findings to a lay person.\n",
    "\n",
    "*Hint: While superficially, the argumentation form task 1 may seem sound, you have the sneaking suspicion that you should look at the two attributes 'race' and 'gender' in combination instead of separately.*\n",
    "\n",
    "*Second hint: You may create a makeshift confusion matrix by creating another pandas dataframe of the four intersectional values and renaming columns and index.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a0ff5063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>expected percentage</th>\n",
       "      <th>real percentage</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>-0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>0.085500</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.085500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>black</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.054000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>asian</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.010500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "      <td>0.347900</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.149100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>female</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>0.084987</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.084987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>female</td>\n",
       "      <td>black</td>\n",
       "      <td>0.053676</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.053676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>female</td>\n",
       "      <td>asian</td>\n",
       "      <td>0.010437</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.010437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>non-binary</td>\n",
       "      <td>white</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>non-binary</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>non-binary</td>\n",
       "      <td>black</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>non-binary</td>\n",
       "      <td>asian</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn\n",
    "\n",
    "employ_num = data.shape[0]\n",
    "races = data[\"race\"].unique()\n",
    "genders = data[\"gender\"].unique()\n",
    "\n",
    "confusion_matrix = pd.DataFrame(columns=[\"gender\", \"race\", \"expected percentage\", \"real percentage\", \"difference\"])\n",
    "\n",
    "# we'll use values calculated in task 1 to simplicity assume that there is no one-dimensional biased hiring policy.\n",
    "expected_gender = {'male': 0.5, 'female': 0.497, 'non-binary': 0.003}\n",
    "expected_race = {'white': 0.7, 'hispanic': 0.171, 'black': 0.108, 'asian': 0.021}\n",
    "\n",
    "size = 0\n",
    "\n",
    "for gender in genders:\n",
    "    for race in races:\n",
    "        # we'll assume for this that the distribution should be independent, if it is, then we have bias.\n",
    "        expected_percentage = expected_gender[gender] * expected_race[race]\n",
    "        real_percentage = (data[(data[\"gender\"] == gender) & (data[\"race\"] == race)]).shape[0] / float(employ_num)\n",
    "\n",
    "        confusion_matrix.loc[size] = [\n",
    "            gender,\n",
    "            race,\n",
    "            expected_percentage,\n",
    "            real_percentage,\n",
    "            real_percentage - expected_percentage\n",
    "        ]\n",
    "        size += 1\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(confusion_matrix.to_html()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a307d9",
   "metadata": {},
   "source": [
    "The results imply that indeed there seems to be a bias against white men and non-white women, which looks like the company is hiring white women to hire women and non-white men to hire non-white people. This is unfair for white men as well as non-white women. Because of the low sample-size I am ignoring the results for non-binary people."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
